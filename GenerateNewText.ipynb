{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import winsound\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Embedding, Dot, Reshape, LSTM\n",
    "\n",
    "\n",
    "maxlen = 40\n",
    "step = 3\n",
    "text = []\n",
    "chars = []\n",
    "sentences = []\n",
    "next_chars = []\n",
    "x = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Collection of  of Functions\n",
    "#\n",
    "\n",
    "def beep():\n",
    "    try:\n",
    "        frequency = 250  # Set Frequency To 2500 Hertz\n",
    "        duration = 100  # Set Duration To 1000 ms == 1 second\n",
    "        winsound.Beep(frequency, duration)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "    finally:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def read_text_file():\n",
    "    try:\n",
    "        global text\n",
    "        \n",
    "        base_path = 'C:/Users/MB/Documents/_WimpyKids/'\n",
    "        filename = 'Book1_10_tight.txt'\n",
    "        path_to_file = os.path.join(base_path, filename)\n",
    "        f = open(path_to_file,'rb')\n",
    "        text=f.read().lower()\n",
    "    except Exception as e:\n",
    "        print(e) #or pass\n",
    "    finally:\n",
    "        print('Corpus Length: ', len(text))\n",
    "        f.close()\n",
    "        beep()    \n",
    "\n",
    "        \n",
    "def break_text_into_parts():\n",
    "    try:\n",
    "        global chars\n",
    "        global x,y\n",
    "        global sentences, next_chars\n",
    "        \n",
    "        \n",
    "        chars = sorted(list(set(text)))\n",
    "        print('total chars:', len(chars))\n",
    "        char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "        indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "        # cut the text in semi-redundant sequences of maxlen characters\n",
    "        maxlen = 40\n",
    "        step = 3\n",
    "        sentences = []\n",
    "        next_chars = []\n",
    "        for i in range(0, len(text) - maxlen, step):\n",
    "            sentences.append(text[i: i + maxlen])\n",
    "            next_chars.append(text[i + maxlen])\n",
    "        print('nb sequences:', len(sentences))\n",
    "\n",
    "        print('Vectorization...')\n",
    "        x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "        y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[i, t, char_indices[char]] = 1\n",
    "            y[i, char_indices[next_chars[i]]] = 1        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        print('Length of Chars: ', len(chars))\n",
    "        \n",
    "        \n",
    "        \n",
    "def sample(preds, temperature=1.0):\n",
    "    try:\n",
    "        # helper function to sample an index from a probability array\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "    except Exception as e:\n",
    "        print(e) #or pass\n",
    "    finally:\n",
    "        pass  \n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    try:\n",
    "        # Function invoked at end of each epoch. Prints generated text.\n",
    "        print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "            print('----- diversity:', diversity)\n",
    "\n",
    "            generated = ''\n",
    "            sentence = text[start_index: start_index + maxlen]\n",
    "            generated += sentence\n",
    "            print('----- Generating with seed: \"' + sentence + '\"')\n",
    "            sys.stdout.write(generated)\n",
    "\n",
    "            for i in range(400):\n",
    "                x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(sentence):\n",
    "                    x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "                preds = model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = sample(preds, diversity)\n",
    "                next_char = indices_char[next_index]\n",
    "\n",
    "                generated += next_char\n",
    "                sentence = sentence[1:] + next_char\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "                sys.stdout.flush()\n",
    "            print()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e) #or pass\n",
    "    finally:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length:  1064208\n"
     ]
    }
   ],
   "source": [
    "read_text_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 90\n",
      "nb sequences: 354723\n",
      "Vectorization...\n",
      "Length of Chars:  90\n"
     ]
    }
   ],
   "source": [
    "break_text_into_parts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From C:\\Users\\MB\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 319250 samples, validate on 35473 samples\n",
      "WARNING:tensorflow:From C:\\Users\\MB\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/5\n",
      "319232/319250 [============================>.] - ETA: 0s - loss: 1.9497 - acc: 0.4418----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "must be str, not bytes\n",
      "319250/319250 [==============================] - 1342s 4ms/sample - loss: 1.9496 - acc: 0.4418 - val_loss: 1.7169 - val_acc: 0.4957\n",
      "Epoch 2/5\n",
      "319232/319250 [============================>.] - ETA: 0s - loss: 1.6404 - acc: 0.5220----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "must be str, not bytes\n",
      "319250/319250 [==============================] - 1357s 4ms/sample - loss: 1.6404 - acc: 0.5220 - val_loss: 1.6302 - val_acc: 0.5172\n",
      "Epoch 3/5\n",
      "319232/319250 [============================>.] - ETA: 0s - loss: 1.5759 - acc: 0.5397----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "must be str, not bytes\n",
      "319250/319250 [==============================] - 1350s 4ms/sample - loss: 1.5759 - acc: 0.5397 - val_loss: 1.6060 - val_acc: 0.5287\n",
      "Epoch 4/5\n",
      "319232/319250 [============================>.] - ETA: 0s - loss: 1.5378 - acc: 0.5503----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "must be str, not bytes\n",
      "319250/319250 [==============================] - 1345s 4ms/sample - loss: 1.5378 - acc: 0.5503 - val_loss: 1.5947 - val_acc: 0.5316\n",
      "Epoch 5/5\n",
      "319232/319250 [============================>.] - ETA: 0s - loss: 1.5185 - acc: 0.5554----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "must be str, not bytes\n",
      "319250/319250 [==============================] - 1389s 4ms/sample - loss: 1.5185 - acc: 0.5554 - val_loss: 1.5813 - val_acc: 0.5343\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               112128    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 90)                11610     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 90)                0         \n",
      "=================================================================\n",
      "Total params: 123,738\n",
      "Trainable params: 123,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "print('Build model...')\n",
    "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "model.fit(x, y, batch_size = 128, epochs = 5, validation_split = 0.1, callbacks = [print_callback])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
